{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning for Handwritten Digit Recognition using CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the labels (target digits) from the pixel values in both datasets.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "train = pd.read_csv('mnist_train.csv')\n",
    "test = pd.read_csv('mnist_test.csv')\n",
    "\n",
    "# Separate the labels and pixel values\n",
    "X_train = train.drop(columns=['label']).values\n",
    "y_train = train['label'].values\n",
    "X_test = test.drop(columns=['label']).values\n",
    "y_test = test['label'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the Pixel Values: The pixel values range from 0 to 255. Normalize them to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the Data: Reshape the flattened pixel values into 28x28 images (with 1 color channel, since they are grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode the Labels: Convert the digit labels (0-9) into one-hot encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a CNN Model: Design a Convolutional Neural Network (CNN) to process the 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ompile the Model: Choose an optimizer (e.g., Adam), a loss function (categorical crossentropy), and a performance metric (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model: Train your model using the training data, experiment with hyperparameters like epochs and batch_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 27ms/step - accuracy: 0.8666 - loss: 0.4445 - val_accuracy: 0.9825 - val_loss: 0.0580\n",
      "Epoch 2/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9817 - loss: 0.0578 - val_accuracy: 0.9840 - val_loss: 0.0544\n",
      "Epoch 3/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9883 - loss: 0.0382 - val_accuracy: 0.9887 - val_loss: 0.0366\n",
      "Epoch 4/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9914 - loss: 0.0287 - val_accuracy: 0.9907 - val_loss: 0.0329\n",
      "Epoch 5/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9925 - loss: 0.0223 - val_accuracy: 0.9877 - val_loss: 0.0418\n",
      "Epoch 6/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9938 - loss: 0.0178 - val_accuracy: 0.9910 - val_loss: 0.0339\n",
      "Epoch 7/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9954 - loss: 0.0139 - val_accuracy: 0.9912 - val_loss: 0.0350\n",
      "Epoch 8/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9962 - loss: 0.0111 - val_accuracy: 0.9915 - val_loss: 0.0321\n",
      "Epoch 9/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9962 - loss: 0.0108 - val_accuracy: 0.9905 - val_loss: 0.0414\n",
      "Epoch 10/10\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9967 - loss: 0.0092 - val_accuracy: 0.9902 - val_loss: 0.0405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x274c96a7590>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key Insights:\n",
    "Training Accuracy and Loss:\n",
    "\n",
    "The model started with an accuracy of 86.59% and a loss of 0.4484 in the first epoch.\n",
    "By the 10th epoch, the accuracy improved significantly to 99.66%, and the loss reduced to 0.0092, which indicates strong learning on the training data.\n",
    "Validation Accuracy and Loss:\n",
    "\n",
    "The validation accuracy started at 98.43% in the first epoch and peaked at 99.22% in the 7th epoch, then slightly decreased to 98.92% by the 10th epoch.\n",
    "The validation loss started at 0.0551, reached a minimum of 0.0308 in the 7th epoch, and then slightly increased to 0.0443 by the 10th epoch.\n",
    "Observations:\n",
    "Overfitting: Around the 7th epoch, the validation loss starts increasing while the validation accuracy plateaus, which could be a sign of slight overfitting. The model is fitting well on the training data but not generalizing as perfectly on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement Early Stopping and Learning Rate Scheduling\n",
    "Why?\n",
    "\n",
    "Early Stopping prevents overfitting by halting training when the model's performance on a validation set stops improving.\n",
    "Learning Rate Scheduling adjusts the learning rate during training, which can lead to better convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9885 - val_loss: 0.0542 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9923 - val_loss: 0.0347 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9907 - val_loss: 0.0396 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21433s\u001b[0m 25s/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9903 - val_loss: 0.0461 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 23ms/step - accuracy: 0.9986 - loss: 0.0037 - val_accuracy: 0.9935 - val_loss: 0.0324 - learning_rate: 2.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 3.3345e-04 - val_accuracy: 0.9932 - val_loss: 0.0349 - learning_rate: 2.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 1.4538e-04 - val_accuracy: 0.9937 - val_loss: 0.0362 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 9.6579e-05 - val_accuracy: 0.9935 - val_loss: 0.0375 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define Early Stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Define Learning Rate Scheduler\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)\n",
    "\n",
    "# Update your model.fit() to include callbacks\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,  # Increased epochs\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "EarlyStopping monitors the validation loss and stops training if it doesn't improve for 3 consecutive epochs.\n",
    "ReduceLROnPlateau reduces the learning rate by a factor of 0.2 if the validation loss doesn't improve for 2 consecutive epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Regularization Techniques\n",
    "Why?\n",
    "\n",
    "Regularization helps in preventing overfitting, ensuring that the model generalizes well to unseen data.\n",
    "How?\n",
    "\n",
    "a. Dropout: Add dropout layers to randomly deactivate neurons during training, reducing over-reliance on specific neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),  # Dropout layer\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Higher dropout in dense layer\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 Regularization: Add L2 penalties to the weights to discourage large weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape=(28, 28, 1)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Incorporate Data Augmentation\n",
    "Why?\n",
    "\n",
    "Data augmentation artificially increases the diversity of the training dataset, helping the model generalize better.\n",
    "How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train and y_train datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m  1/750\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m58:41\u001b[0m 5s/step - accuracy: 0.0938 - loss: 3.4426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - accuracy: 0.7337 - loss: 1.1974 - val_accuracy: 0.9801 - val_loss: 0.3678 - learning_rate: 0.0010\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9801 - val_loss: 0.3678 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 50ms/step - accuracy: 0.9469 - loss: 0.4574 - val_accuracy: 0.9831 - val_loss: 0.2785 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=64),\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),  # Ensure X_val and y_val are defined\n",
    "    steps_per_epoch=X_train.shape[0] // 64,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - accuracy: 0.9409 - loss: 0.4729 - val_accuracy: 0.9854 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: 0.0000e+00 - val_accuracy: 0.9854 - val_loss: 0.2769 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 58ms/step - accuracy: 0.9594 - loss: 0.3507 - val_accuracy: 0.9877 - val_loss: 0.2240 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,       # Rotate images by up to 10 degrees\n",
    "    zoom_range=0.1,          # Zoom images by up to 10%\n",
    "    width_shift_range=0.1,   # Shift images horizontally by up to 10%\n",
    "    height_shift_range=0.1,  # Shift images vertically by up to 10%\n",
    "    shear_range=0.1,         # Shear transformation\n",
    "    horizontal_flip=False    # MNIST digits are not horizontally flipped\n",
    ")\n",
    "\n",
    "# Fit the generator to  training data\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Update model.fit() to use the generator\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=64),\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    steps_per_epoch=X_train.shape[0] // 64,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageDataGenerator applies random transformations to the images during training, creating new, varied samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning\n",
    "Why?\n",
    "\n",
    "Hyperparameter tuning explores different combinations of hyperparameters to find the most optimal configuration for my model.\n",
    "How?\n",
    "\n",
    "a. Manual Tuning: Experiment with different batch sizes, learning rates, number of layers, etc.\n",
    "\n",
    "b. Automated Tuning with Keras Tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 22s]\n",
      "val_accuracy: 0.9859166741371155\n",
      "\n",
      "Best val_accuracy So Far: 0.9925833344459534\n",
      "Total elapsed time: 09h 37m 13s\n",
      "\n",
      "The optimal number of filters in the first Conv2D layer is 128.\n",
      "The optimal number of filters in the second Conv2D layer is 192.\n",
      "The optimal number of units in the Dense layer is 256.\n",
      "The optimal optimizer is adam.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('filters_1', min_value=32, max_value=128, step=32),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1)\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Conv2D(\n",
    "        filters=hp.Int('filters_2', min_value=64, max_value=256, step=64),\n",
    "        kernel_size=(3, 3),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(\n",
    "        units=hp.Int('units', min_value=64, max_value=256, step=64),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'rmsprop']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='mnist_tuning',\n",
    "    project_name='mnist_digit_classification'\n",
    ")\n",
    "\n",
    "tuner.search(datagen.flow(X_train, y_train, batch_size=64), \n",
    "             epochs=50, \n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[early_stop, reduce_lr])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "The optimal number of filters in the first Conv2D layer is {best_hps.get('filters_1')}.\n",
    "The optimal number of filters in the second Conv2D layer is {best_hps.get('filters_2')}.\n",
    "The optimal number of units in the Dense layer is {best_hps.get('units')}.\n",
    "The optimal optimizer is {best_hps.get('optimizer')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Tuner automates the hyperparameter search, testing different configurations to identify the best-performing model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation for Robust Evaluation\n",
    "Why?\n",
    "\n",
    "Cross-validation provides a more reliable estimate of my  model's performance by training and validating it on multiple subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for fold 1 ...\n",
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 112ms/step - accuracy: 0.7303 - loss: 0.8022 - val_accuracy: 0.9810 - val_loss: 0.0570 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 123ms/step - accuracy: 0.9470 - loss: 0.1780 - val_accuracy: 0.9886 - val_loss: 0.0371 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 124ms/step - accuracy: 0.9613 - loss: 0.1288 - val_accuracy: 0.9858 - val_loss: 0.0429 - learning_rate: 0.0010\n",
      "Training for fold 2 ...\n",
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 136ms/step - accuracy: 0.7399 - loss: 0.7660 - val_accuracy: 0.9791 - val_loss: 0.0613 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 130ms/step - accuracy: 0.9454 - loss: 0.1794 - val_accuracy: 0.9861 - val_loss: 0.0487 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 141ms/step - accuracy: 0.9604 - loss: 0.1324 - val_accuracy: 0.9874 - val_loss: 0.0389 - learning_rate: 0.0010\n",
      "Training for fold 3 ...\n",
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 126ms/step - accuracy: 0.7293 - loss: 0.7988 - val_accuracy: 0.9791 - val_loss: 0.0626 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 136ms/step - accuracy: 0.9444 - loss: 0.1878 - val_accuracy: 0.9872 - val_loss: 0.0410 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 129ms/step - accuracy: 0.9576 - loss: 0.1337 - val_accuracy: 0.9852 - val_loss: 0.0437 - learning_rate: 0.0010\n",
      "Training for fold 4 ...\n",
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 139ms/step - accuracy: 0.7411 - loss: 0.7716 - val_accuracy: 0.9753 - val_loss: 0.0822 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 126ms/step - accuracy: 0.9475 - loss: 0.1747 - val_accuracy: 0.9853 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 126ms/step - accuracy: 0.9616 - loss: 0.1322 - val_accuracy: 0.9884 - val_loss: 0.0360 - learning_rate: 0.0010\n",
      "Training for fold 5 ...\n",
      "Epoch 1/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 127ms/step - accuracy: 0.7356 - loss: 0.7870 - val_accuracy: 0.9809 - val_loss: 0.0586 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 124ms/step - accuracy: 0.9483 - loss: 0.1756 - val_accuracy: 0.9862 - val_loss: 0.0419 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 129ms/step - accuracy: 0.9595 - loss: 0.1357 - val_accuracy: 0.9893 - val_loss: 0.0356 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    model = build_model(best_hps)  # Rebuild the model with best hyperparameters\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train_fold, y_train_fold, batch_size=64),\n",
    "        epochs=50,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        callbacks=[early_stop, reduce_lr]\n",
    "    )\n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross-Validation splits the data into k subsets, training the model k times each time using a different subset as the validation set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Model Architectures\n",
    "Why?\n",
    "\n",
    "Exploring more sophisticated architectures can further boost the model's performance.\n",
    "How?\n",
    "\n",
    "a. Implementing Residual Networks (ResNet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_60\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_60\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │ input_layer_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_12… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_13… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6272</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,605,888</span> │ flatten_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_20          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m640\u001b[0m │ input_layer_6[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_12    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_18          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_12… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_13    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_19          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_13… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6272\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │  \u001b[38;5;34m1,605,888\u001b[0m │ flatten_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │      \u001b[38;5;34m1,024\u001b[0m │ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_20          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │      \u001b[38;5;34m2,570\u001b[0m │ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,055,306</span> (7.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,055,306\u001b[0m (7.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,053,642</span> (7.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,053,642\u001b[0m (7.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> (6.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,664\u001b[0m (6.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m378s\u001b[0m 492ms/step - accuracy: 0.8378 - loss: 0.5341 - val_accuracy: 0.9846 - val_loss: 0.0497 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 525ms/step - accuracy: 0.9701 - loss: 0.0991 - val_accuracy: 0.9868 - val_loss: 0.0478 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m386s\u001b[0m 514ms/step - accuracy: 0.9769 - loss: 0.0745 - val_accuracy: 0.9849 - val_loss: 0.0458 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Add\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(filters, kernel_size, activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, activation=None, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = Add()([shortcut, x])\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "input_layer = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(input_layer)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = residual_block(x, 64)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = residual_block(x, 128)\n",
    "x = layers.MaxPooling2D((2,2))(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_layer = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "resnet_model = models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "resnet_model.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "resnet_model.summary()\n",
    "\n",
    "# Train the ResNet model\n",
    "history_resnet = resnet_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=64),\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with Comprehensive Metrics\n",
    "Why?\n",
    "\n",
    "Accuracy alone doesn't provide a complete picture. Additional metrics like confusion matrix, precision, recall, and F1-score offer deeper insights into model performance.\n",
    "How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.99      0.99      1032\n",
      "           3       0.99      1.00      0.99      1010\n",
      "           4       0.99      1.00      0.99       982\n",
      "           5       0.99      0.99      0.99       892\n",
      "           6       1.00      0.98      0.99       958\n",
      "           7       1.00      0.99      0.99      1028\n",
      "           8       1.00      0.99      0.99       974\n",
      "           9       1.00      0.99      0.99      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, y_pred_labels)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(true_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy my Model:\n",
    "\n",
    "Create a simple web application using Flask or Streamlit to demonstrate my model's capabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (24.0)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (4.25.4)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (13.8.1)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (4.11.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from streamlit) (6.4)\n",
      "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-4.0.2-py3-none-win_amd64.whl.metadata (38 kB)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.5.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/8.7 MB 2.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/8.7 MB 3.1 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.1/8.7 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.1/8.7 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.2/8.7 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.2/8.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 5.5/8.7 MB 4.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.6/8.7 MB 3.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.3/8.7 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.7/8.7 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.7/8.7 MB 4.1 MB/s eta 0:00:00\n",
      "Downloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "   ---------------------------------------- 0.0/658.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 658.1/658.1 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Downloading pyarrow-17.0.0-cp311-cp311-win_amd64.whl (25.2 MB)\n",
      "   ---------------------------------------- 0.0/25.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.0/25.2 MB 6.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 2.9/25.2 MB 7.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 3.9/25.2 MB 7.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.2/25.2 MB 6.6 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 6.8/25.2 MB 6.8 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 7.9/25.2 MB 6.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.2/25.2 MB 6.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 10.0/25.2 MB 6.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 11.3/25.2 MB 6.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.8/25.2 MB 6.3 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 13.6/25.2 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.2/25.2 MB 6.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 16.3/25.2 MB 6.2 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 17.3/25.2 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.6/25.2 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.4/25.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.8/25.2 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.5/25.2 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.3/25.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.9/25.2 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.2 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.2/25.2 MB 5.6 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.8/6.9 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.1/6.9 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.9/6.9 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 5.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.7/6.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.9/6.9 MB 4.9 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-4.0.2-py3-none-win_amd64.whl (82 kB)\n",
      "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading narwhals-1.8.1-py3-none-any.whl (166 kB)\n",
      "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, pyarrow, narwhals, jinja2, click, cachetools, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "Successfully installed altair-5.4.1 blinker-1.8.2 cachetools-5.5.0 click-8.1.7 gitdb-4.0.11 gitpython-3.1.43 jinja2-3.1.4 narwhals-1.8.1 pyarrow-17.0.0 pydeck-0.9.1 smmap-5.0.1 streamlit-1.38.0 tenacity-8.5.0 toml-0.10.2 watchdog-4.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 03:56:23.156 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-18 03:56:23.404 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-09-18 03:56:23.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-18 03:56:23.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-18 03:56:23.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-18 03:56:23.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-18 03:56:23.404 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "st.title(\"Handwritten Digit Recognition\")\n",
    "\n",
    "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file).convert('L')\n",
    "    image = image.resize((28, 28))\n",
    "    st.image(image, caption='Uploaded Image', use_column_width=True)\n",
    "    img_array = np.array(image) / 255.0\n",
    "    img_array = img_array.reshape(1, 28, 28, 1)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_label = np.argmax(prediction, axis=1)[0]\n",
    "    st.write(f'Predicted Digit: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate TensorBoard:\n",
    "\n",
    "TensorBoard to visualize training metrics, model graph\n",
    "\n",
    "How?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 120ms/step - accuracy: 0.9513 - loss: 0.1684 - val_accuracy: 0.9934 - val_loss: 0.0257 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 137ms/step - accuracy: 0.9715 - loss: 0.0912 - val_accuracy: 0.9936 - val_loss: 0.0235 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 125ms/step - accuracy: 0.9781 - loss: 0.0771 - val_accuracy: 0.9936 - val_loss: 0.0222 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 125ms/step - accuracy: 0.9792 - loss: 0.0682 - val_accuracy: 0.9944 - val_loss: 0.0212 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 120ms/step - accuracy: 0.9802 - loss: 0.0642 - val_accuracy: 0.9930 - val_loss: 0.0240 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 118ms/step - accuracy: 0.9807 - loss: 0.0639 - val_accuracy: 0.9929 - val_loss: 0.0251 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 126ms/step - accuracy: 0.9840 - loss: 0.0540 - val_accuracy: 0.9948 - val_loss: 0.0191 - learning_rate: 2.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 135ms/step - accuracy: 0.9854 - loss: 0.0491 - val_accuracy: 0.9949 - val_loss: 0.0189 - learning_rate: 2.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 118ms/step - accuracy: 0.9869 - loss: 0.0464 - val_accuracy: 0.9952 - val_loss: 0.0193 - learning_rate: 2.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 120ms/step - accuracy: 0.9860 - loss: 0.0468 - val_accuracy: 0.9945 - val_loss: 0.0189 - learning_rate: 2.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 124ms/step - accuracy: 0.9874 - loss: 0.0416 - val_accuracy: 0.9947 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 127ms/step - accuracy: 0.9882 - loss: 0.0405 - val_accuracy: 0.9948 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 126ms/step - accuracy: 0.9869 - loss: 0.0451 - val_accuracy: 0.9946 - val_loss: 0.0191 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 128ms/step - accuracy: 0.9884 - loss: 0.0428 - val_accuracy: 0.9951 - val_loss: 0.0184 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 127ms/step - accuracy: 0.9884 - loss: 0.0393 - val_accuracy: 0.9950 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 129ms/step - accuracy: 0.9876 - loss: 0.0404 - val_accuracy: 0.9952 - val_loss: 0.0180 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 127ms/step - accuracy: 0.9885 - loss: 0.0379 - val_accuracy: 0.9952 - val_loss: 0.0183 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 132ms/step - accuracy: 0.9893 - loss: 0.0357 - val_accuracy: 0.9950 - val_loss: 0.0179 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='logs')\n",
    "\n",
    "history = model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=64),\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop, reduce_lr, tensorboard]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
